{
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ETL02_Company_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "from pyspark.sql.types import *\r\n",
        "from pyspark.sql import functions as f\r\n",
        "import requests\r\n",
        "import pandas as pd \r\n",
        "from notebookutils import mssparkutils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "outputs": [],
      "metadata": {},
      "source": [
        "# get data from api \n",
        "def get_financial_statement(symbol,limit,apikey):\n",
        "    url ='https://financialmodelingprep.com/api/v3/financial-statement-full-as-reported/{0}?period=annual&limit={1}&apikey={2}'.format(symbol,limit,apikey)\n",
        "    r = requests.get(url)\n",
        "    data = r.json()\n",
        "    return data\n",
        "# turn pandas df into spark datafrme and change scheme\n",
        "def read_into_sp(dataframe):\n",
        "    result = (spark.createDataFrame(dataframe))\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "if __name__ == \"__main__\":\r\n",
        "    \r\n",
        "    # apikey = mssparkutils.credentials.getSecret('synapse-key1234','fmp-key')\r\n",
        "    # # set up target ticker \r\n",
        "    # symbol_list=['NVDA','AMD','INTC','QCOM','GOOG','MSFT','AMZN','AAPL']\r\n",
        "    # # get data from api\r\n",
        "    # stock_data = [get_financial_statement(symbol,5,apikey) for symbol in symbol_list]\r\n",
        "    list_ = [pd.DataFrame(data) for data in stock_data]\r\n",
        "    selected_columns=[\r\n",
        "        \"date\",\"symbol\",\"period\",\"documenttype\",\"revenues\",\"costofrevenue\",\r\n",
        "        \"grossprofit\",\"netincomeloss\",\"earningspersharebasic\",\"earningspersharediluted\",\"operatingincomeloss\",\r\n",
        "        \"operatingexpenses\",\"researchanddevelopmentexpense\",\"sellinggeneralandadministrativeexpense\",\r\n",
        "        \"interestexpense\",\"cashandcashequivalentsatcarryingvalue\",\"commonstocksharesoutstanding\",\"longtermdebt\"\r\n",
        "    ]\r\n",
        "    pdfs = (pd.concat(list_ ))[[*selected_columns]]\r\n",
        "    final_df_sp = read_into_sp(pdfs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "#add year \r\n",
        "datalake_nm = 'datalake'+mssparkutils.env.getWorkspaceName()[7:] # get datalake name\r\n",
        "file_path ='abfss://files@{0}.dfs.core.windows.net/synapse/workspaces/data/company_report'.format(datalake_nm)\r\n",
        "final_df_sp.write.option(\"header\", True).csv(file_path,mode='overwrite')"
      ]
    }
  ],
  "metadata": {
    "description": null,
    "save_output": true,
    "language_info": {
      "name": "python"
    }
  }
}