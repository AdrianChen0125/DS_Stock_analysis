{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## ETL01_Stock_price"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import *\n",
        "from pyspark.sql import functions as f\n",
        "import requests\n",
        "import pandas as pd \n",
        "from datetime import datetime, timedelta\n",
        "from notebookutils import mssparkutils\n",
        "\n",
        "# get data from api \n",
        "def get_stock_data(symbol,time_from,data_size,apikey):\n",
        "    url = 'https://www.alphavantage.co/query?function=NEWS_SENTIMENT&symbol={0}&time_from={1}&limit={2}&apikey={3}'.format(symbol,time_from,data_size,apikey)\n",
        "    r = requests.get(url)\n",
        "    data = r.json()\n",
        "    return data\n",
        "\n",
        "def transform_pdf(news_list):\n",
        "    dfs=[]\n",
        "    for news in news_list:\n",
        "        df = pd.DataFrame.from_dict(news['feed'])\n",
        "        dfs.append(df)\n",
        "    pdf = pd.concat(dfs).drop_duplicates(subset=['title'])\n",
        "    pdf_v1 = pdf[['title','time_published','source','ticker_sentiment']]\n",
        "    return pdf_v1"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "spark001",
              "session_id": "14",
              "statement_id": 92,
              "statement_ids": [
                92
              ],
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2024-06-22T15:26:33.4781764Z",
              "session_start_time": null,
              "execution_start_time": "2024-06-22T15:26:33.5854125Z",
              "execution_finish_time": "2024-06-22T15:26:33.7247086Z",
              "spark_jobs": null,
              "parent_msg_id": "ede4bf47-1ed3-494f-b204-a69d50f6949c"
            },
            "text/plain": "StatementMeta(spark001, 14, 92, Finished, Available)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 91,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # get apikey from key-vault \n",
        "    apikey = mssparkutils.credentials.getSecret('synapse-key123','alphavantage-key')\n",
        "    data_size=200\n",
        "    # set up target ticker \n",
        "    symbol_list=['NVDA','AMD','INTC','QCOM','GOOG','MSFT','AMZN','AAPL']\n",
        "    # Get the current datetime\n",
        "    now = datetime.now()\n",
        "\n",
        "    # 30 days to the current datetime\n",
        "    future_date = now - timedelta(days=30)\n",
        "\n",
        "    # Format both datetime objects as 'YYYYMMDDTHHMM'\n",
        "    formatted_now = now.strftime('%Y%m%dT%H%M')\n",
        "    time_from = future_date.strftime('%Y%m%dT%H%M')\n",
        "    # get data from api\n",
        "    stock_news = [get_stock_data(symbol,time_from,data_size,apikey) for symbol in symbol_list]\n",
        "    pdf = transform_pdf(stock_news)\n",
        "    sp_df = spark.createDataFrame(pdf).filter(f.size(f.col('ticker_sentiment')) > 0)\n",
        "\n",
        "    sp_df_v1 = (\n",
        "        sp_df.select('title','time_published','source',f.explode('ticker_sentiment').alias(\"ticker_sentiment\"))\n",
        "        .select('title','time_published','source','ticker_sentiment.*')\n",
        "        .filter(f.col('ticker').isin(symbol_list))\n",
        "                    )"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "spark001",
              "session_id": "14",
              "statement_id": 88,
              "statement_ids": [
                88
              ],
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2024-06-22T15:23:31.8521696Z",
              "session_start_time": null,
              "execution_start_time": "2024-06-22T15:23:31.9634921Z",
              "execution_finish_time": "2024-06-22T15:23:33.0290975Z",
              "spark_jobs": null,
              "parent_msg_id": "f9aea24b-8dbe-4a3f-9e3b-5c1f8faffedf"
            },
            "text/plain": "StatementMeta(spark001, 14, 88, Finished, Available)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 87,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "    print('load data into filepath')\r\n",
        "    #add year column  \r\n",
        "    file_path ='abfss://files@datalake9vbgk2l.dfs.core.windows.net/synapse/workspaces/data/stock_news'\r\n",
        "    sp_df_v1.write.option(\"header\", True).csv(file_path,mode='overwrite')"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "spark001",
              "session_id": "14",
              "statement_id": 100,
              "statement_ids": [
                100
              ],
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2024-06-22T15:30:29.9382514Z",
              "session_start_time": null,
              "execution_start_time": "2024-06-22T15:30:30.0515737Z",
              "execution_finish_time": "2024-06-22T15:30:35.3087904Z",
              "spark_jobs": null,
              "parent_msg_id": "63c71b3b-2a0a-43a0-aa3d-a4eac96b4b2b"
            },
            "text/plain": "StatementMeta(spark001, 14, 100, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "load data into filepath\n"
          ]
        }
      ],
      "execution_count": 99,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "synapse_pyspark",
      "language": "Python",
      "display_name": "Synapse PySpark"
    },
    "kernel_info": {
      "name": "synapse_pyspark"
    },
    "description": null,
    "save_output": true,
    "synapse_widget": {
      "version": "0.1",
      "state": {}
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}