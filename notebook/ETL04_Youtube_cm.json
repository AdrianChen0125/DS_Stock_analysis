{
	"name": "ETL04_Youtube_cm",
	"properties": {
		"folder": {
			"name": "ETL"
		},
		"nbformat": 4,
		"nbformat_minor": 2,
		"sessionProperties": {
			"driverMemory": "28g",
			"driverCores": 4,
			"executorMemory": "28g",
			"executorCores": 4,
			"numExecutors": 2,
			"conf": {
				"spark.dynamicAllocation.enabled": "false",
				"spark.dynamicAllocation.minExecutors": "2",
				"spark.dynamicAllocation.maxExecutors": "2",
				"spark.autotune.trackingId": "e82ef9a7-4d73-49c1-bbcd-3ceb36359145"
			}
		},
		"metadata": {
			"saveOutput": true,
			"enableDebugMode": false,
			"kernelspec": {
				"name": "synapse_pyspark",
				"display_name": "python"
			},
			"language_info": {
				"name": "python"
			},
			"sessionKeepAliveTimeout": 30
		},
		"cells": [
			{
				"cell_type": "markdown",
				"metadata": {
					"id": "jF_ENh3atCvf"
				},
				"source": [
					"# 04 Extract comments from Youtube"
				]
			},
			{
				"cell_type": "code",
				"source": [
					"!pip3 install google-api-python-client\n",
					"!pip install clean-text"
				],
				"execution_count": 2
			},
			{
				"cell_type": "code",
				"source": [
					"from googleapiclient.discovery import build\n",
					"import googleapiclient.errors\n",
					"from datetime import datetime, timezone, timedelta\n",
					"import pandas as pd\n",
					"from notebookutils import mssparkutils"
				],
				"execution_count": 3
			},
			{
				"cell_type": "code",
				"source": [
					"# create connection\n",
					"def set_up_youtube(api_service_name,api_version,DEVELOPER_KEY):\n",
					"    youtube = googleapiclient.discovery.build(api_service_name, api_version, developerKey=DEVELOPER_KEY)\n",
					"    return youtube \n",
					"    \n",
					"# serch for video list \n",
					"def get_video_object(youtube,query,publishedAf,order_type):\n",
					"    \n",
					"    # request for video based on your query \n",
					"    search_response = youtube.search().list(\n",
					"        q=query,\n",
					"        type='video',\n",
					"        part='id,snippet',\n",
					"        maxResults=30,\n",
					"        publishedAfter= publishedAf,\n",
					"        order=order_type\n",
					"    ).execute()\n",
					"\n",
					"    #get video object from the response \n",
					"    videos = []\n",
					"    for search_result in search_response.get('items', []):\n",
					"        video = {\n",
					"                'title': search_result['snippet']['title'],\n",
					"                'id': search_result['id']['videoId'],\n",
					"                'url': f\"https://www.youtube.com/watch?v={search_result['id']['videoId']}\",\n",
					"                'video_id': search_result['id']['videoId'],\n",
					"                'CreatedAt':search_result['snippet']['publishedAt']\n",
					"            }\n",
					"\n",
					"        videos.append(video)\n",
					"    return videos\n",
					"\n",
					"# Function to get all comments (including replies) for a single video\n",
					"\n",
					"def get_comments_for_video(youtube, video_id):\n",
					"    all_comments = []\n",
					"    next_page_token = None\n",
					"\n",
					"    while True:\n",
					"        try:\n",
					"            comment_request = youtube.commentThreads().list(\n",
					"                part=\"snippet\",\n",
					"                videoId=video_id,\n",
					"                pageToken=next_page_token,\n",
					"                textFormat=\"plainText\",\n",
					"                maxResults=100\n",
					"            )\n",
					"            comment_response = comment_request.execute()\n",
					"\n",
					"            for item in comment_response['items']:\n",
					"                top_comment = item['snippet']['topLevelComment']['snippet']\n",
					"                all_comments.append({\n",
					"                    'Timestamp': top_comment['publishedAt'],\n",
					"                    'Username': top_comment['authorDisplayName'],\n",
					"                    'VideoID': video_id,\n",
					"                    'Comment': top_comment['textDisplay'],\n",
					"                    'Date': top_comment['updatedAt'] if 'updatedAt' in top_comment else top_comment['publishedAt']\n",
					"                })\n",
					"\n",
					"            next_page_token = comment_response.get('nextPageToken')\n",
					"            if not next_page_token:\n",
					"                break\n",
					"\n",
					"        except googleapiclient.errors.HttpError as e:\n",
					"            error_content = e.content.decode(\"utf-8\")\n",
					"            if 'commentsDisabled' in error_content or 'disabled comments' in error_content:\n",
					"                # Ignore videos with disabled comments\n",
					"                print(f\"Comments are disabled for the video with ID {video_id}. Ignoring this video.\")\n",
					"                break  # Exit the loop\n",
					"            else:\n",
					"                print(f\"An error occurred: {e}\")\n",
					"                break  # Exit the loop\n",
					"    \n",
					"    return all_comments"
				],
				"execution_count": 4
			},
			{
				"cell_type": "code",
				"source": [
					"if __name__ == '__main__':\n",
					"    # set up youtube search engine\n",
					"    api_service_name = \"youtube\"\n",
					"    api_version = \"v3\"\n",
					"    DEVELOPER_KEY= mssparkutils.credentials.getSecret('synapse-key12345','youtube-key')\n",
					"    \n",
					"    youtube = set_up_youtube(api_service_name,api_version,DEVELOPER_KEY)\n",
					"    \n",
					"    # set up date range \n",
					"    bf_30 = datetime.now(timezone.utc)-timedelta(days=60)\n",
					"    iso_format_with_z = bf_30 .isoformat().replace('+00:00', 'Z')\n",
					"    symbol_list=['NVDA','AMD','INTC','QCOM','GOOG','MSFT','AMZN','AAPL']\n",
					"    \n",
					"    # collect comments\n",
					"    all_stocks_cm = []\n",
					"    for symbol in symbol_list:\n",
					"        video_list = get_video_object(youtube,f'{symbol} stock',iso_format_with_z,order_type='viewCount')\n",
					"        video_ids= [i['video_id'] for i in video_list]\n",
					"        \n",
					"        all_comments=[]\n",
					"        for video_id in video_ids:\n",
					"            video_comments = get_comments_for_video(youtube, video_id)\n",
					"            all_comments.extend(video_comments)\n",
					"            \n",
					"        comments_df = pd.DataFrame(all_comments)\n",
					"        comments_df['resource'] = 'Youtube'\n",
					"        comments_df['symbol'] = symbol\n",
					"        all_stocks_cm.append(comments_df)\n",
					"        \n",
					"    df = pd.concat(all_stocks_cm)\n",
					"    df['collectedAt'] = datetime.now().date()\n",
					"\n",
					"    # read into spark dataframe and write into csv \n",
					"    spark_df = spark.createDataFrame(df)\n",
					"    datalake_nm = 'datalake'+mssparkutils.env.getWorkspaceName()[7:] # get datalake name \n",
					"    file_path ='abfss://files@{0}.dfs.core.windows.net/synapse/workspaces/data/youtube/youtube_cms'.format(datalake_nm)\n",
					"    spark_df.write.parquet(file_path,mode='overwrite')\n",
					"    spark.stop()"
				],
				"execution_count": 5
			}
		]
	}
}