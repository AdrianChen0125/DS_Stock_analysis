{
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "spark0623",
              "session_id": "19",
              "statement_id": 63,
              "statement_ids": [
                63
              ],
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2024-06-23T13:18:41.3854879Z",
              "session_start_time": null,
              "execution_start_time": "2024-06-23T13:18:41.5072094Z",
              "execution_finish_time": "2024-06-23T13:18:44.3456343Z",
              "spark_jobs": null,
              "parent_msg_id": "b9a643c0-c249-4e94-b36e-4fbe43f72b3d"
            },
            "text/plain": "StatementMeta(spark0623, 19, 63, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Requirement already satisfied: vaderSentiment in /home/trusted-service-user/cluster-env/env/lib/python3.10/site-packages (3.3.2)\r\nRequirement already satisfied: langdetect in /home/trusted-service-user/cluster-env/env/lib/python3.10/site-packages (1.0.9)\r\nRequirement already satisfied: emoji in /home/trusted-service-user/cluster-env/env/lib/python3.10/site-packages (2.12.1)\r\nRequirement already satisfied: nltk in /home/trusted-service-user/cluster-env/env/lib/python3.10/site-packages (3.8.1)\r\nRequirement already satisfied: requests in /home/trusted-service-user/cluster-env/env/lib/python3.10/site-packages (from vaderSentiment) (2.31.0)\r\nRequirement already satisfied: six in /home/trusted-service-user/cluster-env/env/lib/python3.10/site-packages (from langdetect) (1.16.0)\r\nRequirement already satisfied: typing-extensions>=4.7.0 in /home/trusted-service-user/cluster-env/env/lib/python3.10/site-packages (from emoji) (4.10.0)\r\nRequirement already satisfied: click in /home/trusted-service-user/cluster-env/env/lib/python3.10/site-packages (from nltk) (8.1.7)\r\nRequirement already satisfied: joblib in /home/trusted-service-user/cluster-env/env/lib/python3.10/site-packages (from nltk) (1.3.2)\r\nRequirement already satisfied: regex>=2021.8.3 in /home/trusted-service-user/cluster-env/env/lib/python3.10/site-packages (from nltk) (2023.12.25)\r\nRequirement already satisfied: tqdm in /home/trusted-service-user/cluster-env/env/lib/python3.10/site-packages (from nltk) (4.66.2)\r\nRequirement already satisfied: charset-normalizer<4,>=2 in /home/trusted-service-user/cluster-env/env/lib/python3.10/site-packages (from requests->vaderSentiment) (3.3.2)\r\nRequirement already satisfied: idna<4,>=2.5 in /home/trusted-service-user/cluster-env/env/lib/python3.10/site-packages (from requests->vaderSentiment) (3.6)\r\nRequirement already satisfied: urllib3<3,>=1.21.1 in /home/trusted-service-user/cluster-env/env/lib/python3.10/site-packages (from requests->vaderSentiment) (2.1.0)\r\nRequirement already satisfied: certifi>=2017.4.17 in /home/trusted-service-user/cluster-env/env/lib/python3.10/site-packages (from requests->vaderSentiment) (2024.2.2)\r\n"
        }
      ],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "!pip install vaderSentiment langdetect emoji nltk vaderSentiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "spark0623",
              "session_id": "19",
              "statement_id": 64,
              "statement_ids": [
                64
              ],
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2024-06-23T13:21:02.3347369Z",
              "session_start_time": null,
              "execution_start_time": "2024-06-23T13:21:02.4777243Z",
              "execution_finish_time": "2024-06-23T13:21:07.8568051Z",
              "spark_jobs": null,
              "parent_msg_id": "715561c0-a2b2-4233-8d41-e0086c4eb180"
            },
            "text/plain": "StatementMeta(spark0623, 19, 64, Finished, Available)"
          },
          "metadata": {}
        }
      ],
      "metadata": {},
      "source": [
        "from pyspark.sql.functions import udf,monotonically_increasing_id\r\n",
        "from pyspark.sql.types import StringType, FloatType\r\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\r\n",
        "from pyspark.sql import functions as f  \r\n",
        "import requests\r\n",
        "import pandas as pd \r\n",
        "import datetime\r\n",
        "import emoji\r\n",
        "import nltk\r\n",
        "from langdetect import detect\r\n",
        "from langdetect.lang_detect_exception import LangDetectException\r\n",
        "from nltk.corpus import stopwords\r\n",
        "from nltk.tokenize import word_tokenize\r\n",
        "import string\r\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\r\n",
        "from notebookutils import mssparkutils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "spark0623",
              "session_id": "19",
              "statement_id": 67,
              "statement_ids": [
                67
              ],
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2024-06-23T13:21:52.7815977Z",
              "session_start_time": null,
              "execution_start_time": "2024-06-23T13:21:52.9080716Z",
              "execution_finish_time": "2024-06-23T13:21:54.0015297Z",
              "spark_jobs": null,
              "parent_msg_id": "186a0a79-22ed-4cab-a85d-2a39f285aed5"
            },
            "text/plain": "StatementMeta(spark0623, 19, 67, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "[nltk_data] Downloading package punkt to /home/trusted-service-\n[nltk_data]     user/nltk_data...\n[nltk_data]   Unzipping tokenizers/punkt.zip.\n[nltk_data] Downloading package stopwords to /home/trusted-service-\n[nltk_data]     user/nltk_data...\n[nltk_data]   Unzipping corpora/stopwords.zip.\n"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "True"
          },
          "execution_count": 135,
          "metadata": {}
        }
      ],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "nltk.download('punkt')\r\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "spark0623",
              "session_id": "19",
              "statement_id": 45,
              "statement_ids": [
                45
              ],
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2024-06-23T13:07:34.4852974Z",
              "session_start_time": null,
              "execution_start_time": "2024-06-23T13:07:38.9810328Z",
              "execution_finish_time": "2024-06-23T13:07:39.5401776Z",
              "spark_jobs": null,
              "parent_msg_id": "e935f56c-fbc9-48e9-902e-d46208a1641c"
            },
            "text/plain": "StatementMeta(spark0623, 19, 45, Finished, Available)"
          },
          "metadata": {}
        }
      ],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "reddit_df = spark.read.parquet('abfss://files@datalakey4zmcph.dfs.core.windows.net/synapse/workspaces/data/reddit_cms/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "spark0623",
              "session_id": "19",
              "statement_id": 113,
              "statement_ids": [
                113
              ],
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2024-06-23T13:51:30.6821682Z",
              "session_start_time": null,
              "execution_start_time": "2024-06-23T13:51:30.8035919Z",
              "execution_finish_time": "2024-06-23T13:51:31.3454023Z",
              "spark_jobs": null,
              "parent_msg_id": "28b5920d-75a2-4141-b51e-b99888d07c59"
            },
            "text/plain": "StatementMeta(spark0623, 19, 113, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "+-------------------+--------------------+------+-----------+\n|        created_utc|             comment|symbol|collectedAt|\n+-------------------+--------------------+------+-----------+\n|2024-05-29 16:27:25|Buy a few that ta...|  NVDA| 2024-06-23|\n|2024-05-29 16:27:00|Buy VT and dont w...|  NVDA| 2024-06-23|\n|2024-05-29 16:26:18|You and me both, ...|  NVDA| 2024-06-23|\n|2024-05-29 16:26:18|There's a reason ...|  NVDA| 2024-06-23|\n|2024-05-29 16:22:20|Your buying perce...|  NVDA| 2024-06-23|\n|2024-05-29 16:20:18|Just comfort your...|  NVDA| 2024-06-23|\n|2024-05-29 16:18:15|as long as that m...|  NVDA| 2024-06-23|\n|2024-05-29 16:14:46|Simple rule.\\nDon...|  NVDA| 2024-06-23|\n|2024-05-29 16:11:39|You sold for a re...|  NVDA| 2024-06-23|\n|2024-05-29 16:11:07|Try and hold for ...|  NVDA| 2024-06-23|\n|2024-05-29 16:03:39|Just buy into ano...|  NVDA| 2024-06-23|\n|2024-05-29 16:01:55|Another thing to ...|  NVDA| 2024-06-23|\n|2024-05-29 16:01:38|Not the worst but...|  NVDA| 2024-06-23|\n|2024-05-29 15:59:27|I sold an ASS loa...|  NVDA| 2024-06-23|\n|2024-05-29 15:57:55|Learn from the mi...|  NVDA| 2024-06-23|\n|2024-05-29 15:57:29|Every investor go...|  NVDA| 2024-06-23|\n|2024-05-29 15:57:27|Just get over it ...|  NVDA| 2024-06-23|\n|2024-05-29 15:57:18|Itâ€™s called a lea...|  NVDA| 2024-06-23|\n|2024-05-29 15:57:02|I had a $2.5k pos...|  NVDA| 2024-06-23|\n|2024-05-29 15:51:47|It doesn't matter...|  NVDA| 2024-06-23|\n+-------------------+--------------------+------+-----------+\nonly showing top 20 rows\n\n"
        }
      ],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "reddit_df.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "spark0623",
              "session_id": "19",
              "statement_id": 114,
              "statement_ids": [
                114
              ],
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2024-06-23T13:51:41.8469834Z",
              "session_start_time": null,
              "execution_start_time": "2024-06-23T13:51:41.9788819Z",
              "execution_finish_time": "2024-06-23T13:51:42.5234401Z",
              "spark_jobs": null,
              "parent_msg_id": "cce93d33-f266-4da3-9e40-c62f714448ce"
            },
            "text/plain": "StatementMeta(spark0623, 19, 114, Finished, Available)"
          },
          "metadata": {}
        }
      ],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "reddit_df_v1 = (\r\n",
        "    reddit_df.withColumn('wordCount', f.size(f.split(f.col('comment'), ' ')))\r\n",
        "    .filter(f.col('wordCount')>5)\r\n",
        "    .withColumn(\"id\", monotonically_increasing_id())\r\n",
        "    .select('created_utc','id','comment','symbol')\r\n",
        "    ).toPandas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "spark0623",
              "session_id": "19",
              "statement_id": 116,
              "statement_ids": [
                116
              ],
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2024-06-23T13:51:48.2731033Z",
              "session_start_time": null,
              "execution_start_time": "2024-06-23T13:51:48.4266937Z",
              "execution_finish_time": "2024-06-23T13:51:48.5839068Z",
              "spark_jobs": null,
              "parent_msg_id": "53f67fd7-117d-4c5a-864a-397f867e9b05"
            },
            "text/plain": "StatementMeta(spark0623, 19, 116, Finished, Available)"
          },
          "metadata": {}
        }
      ],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# remove non english word\r\n",
        "def is_english(text):\r\n",
        "    try:\r\n",
        "        return detect(text) == 'en'\r\n",
        "    except LangDetectException:\r\n",
        "        return False\r\n",
        "    \r\n",
        "# change text into lowercase\r\n",
        "def to_lowercase(text):\r\n",
        "    return text.lower()\r\n",
        "\r\n",
        "# remove punctuation\r\n",
        "def rm_punctuation(text):\r\n",
        "    return text.translate(str.maketrans('', '', string.punctuation))\r\n",
        "\r\n",
        "def tokenise(text):\r\n",
        "    return word_tokenize(text)\r\n",
        "\r\n",
        "# remove stop words \r\n",
        "def remove_stopwords(tokens):\r\n",
        "    stop_words = set(stopwords.words('english'))\r\n",
        "    return [word for word in tokens if word not in stop_words]\r\n",
        "\r\n",
        "# rejoin tokens\r\n",
        "def rejoin_tokens(tokens):\r\n",
        "    return ' '.join(tokens)\r\n",
        "\r\n",
        "# main function for preprocess_text \r\n",
        "def preprocess_text(text):\r\n",
        "    text = to_lowercase(text)\r\n",
        "    text = rm_punctuation(text)\r\n",
        "    tokens = tokenise(text)\r\n",
        "    tokens = remove_stopwords(tokens)\r\n",
        "    return rejoin_tokens(tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "spark0623",
              "session_id": "19",
              "statement_id": 117,
              "statement_ids": [
                117
              ],
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2024-06-23T13:51:51.4047039Z",
              "session_start_time": null,
              "execution_start_time": "2024-06-23T13:51:51.5320852Z",
              "execution_finish_time": "2024-06-23T13:52:00.2068634Z",
              "spark_jobs": null,
              "parent_msg_id": "58293d70-881b-408b-9df7-fea3f87eb8c1"
            },
            "text/plain": "StatementMeta(spark0623, 19, 117, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "/tmp/ipykernel_78401/1873903993.py:3: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  reddit_df_v2['preprocessed_text'] = reddit_df_v2['comment'].apply(preprocess_text)\n"
        }
      ],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "reddit_df_v1['is_english'] = reddit_df_v1['comment'].apply(is_english)\r\n",
        "reddit_df_v2 = reddit_df_v1[reddit_df_v1['is_english']]\r\n",
        "reddit_df_v2['preprocessed_text'] = reddit_df_v2['comment'].apply(preprocess_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "spark0623",
              "session_id": "19",
              "statement_id": 118,
              "statement_ids": [
                118
              ],
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2024-06-23T13:52:02.8468945Z",
              "session_start_time": null,
              "execution_start_time": "2024-06-23T13:52:02.9762936Z",
              "execution_finish_time": "2024-06-23T13:52:03.142622Z",
              "spark_jobs": null,
              "parent_msg_id": "721cb62c-6828-403e-acbe-d6896773c4f1"
            },
            "text/plain": "StatementMeta(spark0623, 19, 118, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "/tmp/ipykernel_78401/136230020.py:4: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  reddit_df_v2['is_string']=reddit_df_v2['preprocessed_text'].apply(is_string)\n"
        }
      ],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "def is_string(text):\r\n",
        "    return isinstance(text, str)\r\n",
        "\r\n",
        "reddit_df_v2['is_string']=reddit_df_v2['preprocessed_text'].apply(is_string)\r\n",
        "reddit_df_v3 = reddit_df_v2[reddit_df_v2['is_string']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "spark0623",
              "session_id": "19",
              "statement_id": 119,
              "statement_ids": [
                119
              ],
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2024-06-23T13:52:05.7485071Z",
              "session_start_time": null,
              "execution_start_time": "2024-06-23T13:52:05.8825602Z",
              "execution_finish_time": "2024-06-23T13:52:06.0499486Z",
              "spark_jobs": null,
              "parent_msg_id": "0e294637-5d3e-4617-b98a-4eeddee50596"
            },
            "text/plain": "StatementMeta(spark0623, 19, 119, Finished, Available)"
          },
          "metadata": {}
        }
      ],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "def analyze_sentiment(text):\r\n",
        "    analyzer = SentimentIntensityAnalyzer()\r\n",
        "    scores = analyzer.polarity_scores(text)\r\n",
        "    return scores['compound']\r\n",
        "\r\n",
        "def categorize_sentiment(compound_score):\r\n",
        "    if compound_score >= 0.05:\r\n",
        "        return 'positive'\r\n",
        "    elif compound_score <= -0.05:\r\n",
        "        return 'negative'\r\n",
        "    else:\r\n",
        "        return 'neutral'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "spark0623",
              "session_id": "19",
              "statement_id": 120,
              "statement_ids": [
                120
              ],
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2024-06-23T13:52:08.4411778Z",
              "session_start_time": null,
              "execution_start_time": "2024-06-23T13:52:08.5759476Z",
              "execution_finish_time": "2024-06-23T13:52:23.2917523Z",
              "spark_jobs": null,
              "parent_msg_id": "941e39ed-f612-4184-ab7f-52022a1381cb"
            },
            "text/plain": "StatementMeta(spark0623, 19, 120, Finished, Available)"
          },
          "metadata": {}
        }
      ],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "reddit_df_v3['sentiment'] = reddit_df_v3['preprocessed_text'].apply(analyze_sentiment)\r\n",
        "reddit_df_v3['sentiment_category'] = reddit_df_v3['sentiment'].apply(categorize_sentiment)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "spark0623",
              "session_id": "19",
              "statement_id": 121,
              "statement_ids": [
                121
              ],
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2024-06-23T13:52:26.2010032Z",
              "session_start_time": null,
              "execution_start_time": "2024-06-23T13:52:26.3257935Z",
              "execution_finish_time": "2024-06-23T13:52:26.4887992Z",
              "spark_jobs": null,
              "parent_msg_id": "57fa7d30-01b9-4bc8-b9db-83612ce72186"
            },
            "text/plain": "StatementMeta(spark0623, 19, 121, Finished, Available)"
          },
          "metadata": {}
        }
      ],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "reddit_df_v4 = reddit_df_v3[['id','created_utc','sentiment','sentiment_category']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "spark0623",
              "session_id": "19",
              "statement_id": 122,
              "statement_ids": [
                122
              ],
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2024-06-23T13:52:28.3559908Z",
              "session_start_time": null,
              "execution_start_time": "2024-06-23T13:52:28.4795101Z",
              "execution_finish_time": "2024-06-23T13:52:28.6340744Z",
              "spark_jobs": null,
              "parent_msg_id": "5518d0d8-837b-4377-97a3-6a1a5428d912"
            },
            "text/plain": "StatementMeta(spark0623, 19, 122, Finished, Available)"
          },
          "metadata": {}
        }
      ],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "final_df = pd.merge(reddit_df_v1,reddit_df_v4, left_on='id', right_on='id', how='left')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "spark0623",
              "session_id": "19",
              "statement_id": 125,
              "statement_ids": [
                125
              ],
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2024-06-23T13:53:07.4504725Z",
              "session_start_time": null,
              "execution_start_time": "2024-06-23T13:53:07.5798548Z",
              "execution_finish_time": "2024-06-23T13:53:07.7366101Z",
              "spark_jobs": null,
              "parent_msg_id": "a9e34dbc-99d7-4fe4-8158-f19638de9e9b"
            },
            "text/plain": "StatementMeta(spark0623, 19, 125, Finished, Available)"
          },
          "metadata": {}
        }
      ],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "result = final_df[['created_utc_x','symbol','comment','sentiment','sentiment_category']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "spark0623",
              "session_id": "19",
              "statement_id": 128,
              "statement_ids": [
                128
              ],
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2024-06-23T13:55:05.066367Z",
              "session_start_time": null,
              "execution_start_time": "2024-06-23T13:55:05.2346585Z",
              "execution_finish_time": "2024-06-23T13:55:08.0475041Z",
              "spark_jobs": null,
              "parent_msg_id": "6e66aab4-75c8-477d-ac45-d753da91c5d0"
            },
            "text/plain": "StatementMeta(spark0623, 19, 128, Finished, Available)"
          },
          "metadata": {}
        }
      ],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "spdf = spark.createDataFrame(result)\r\n",
        "datalake_nm = 'datalake'+mssparkutils.env.getWorkspaceName()[7:] # get datalake name \r\n",
        "file_path ='abfss://files@{0}.dfs.core.windows.net/synapse/workspaces/data/reddit_sentiments'.format(datalake_nm)\r\n",
        "spdf.write.parquet(file_path,mode='overwrite')"
      ]
    }
  ],
  "metadata": {
    "description": null,
    "save_output": true,
    "language_info": {
      "name": "python"
    },
    "synapse_widget": {
      "version": "0.1",
      "state": {}
    }
  }
}