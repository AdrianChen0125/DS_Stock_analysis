{
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Sentiment analysis on Youtube"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "spark0624",
              "session_id": "9",
              "statement_id": 8,
              "statement_ids": [
                8
              ],
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2024-06-24T12:28:43.8654444Z",
              "session_start_time": null,
              "execution_start_time": "2024-06-24T12:28:44.0422623Z",
              "execution_finish_time": "2024-06-24T12:28:46.9058281Z",
              "spark_jobs": null,
              "parent_msg_id": "1f37ac6f-70a3-48c3-821f-82ce26e7c1a7"
            },
            "text/plain": "StatementMeta(spark0624, 9, 8, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Requirement already satisfied: vaderSentiment in /home/trusted-service-user/cluster-env/env/lib/python3.10/site-packages (3.3.2)\r\nRequirement already satisfied: langdetect in /home/trusted-service-user/cluster-env/env/lib/python3.10/site-packages (1.0.9)\r\nRequirement already satisfied: emoji in /home/trusted-service-user/cluster-env/env/lib/python3.10/site-packages (1.7.0)\r\nRequirement already satisfied: nltk in /home/trusted-service-user/cluster-env/env/lib/python3.10/site-packages (3.8.1)\r\nRequirement already satisfied: requests in /home/trusted-service-user/cluster-env/env/lib/python3.10/site-packages (from vaderSentiment) (2.31.0)\r\nRequirement already satisfied: six in /home/trusted-service-user/cluster-env/env/lib/python3.10/site-packages (from langdetect) (1.16.0)\r\nRequirement already satisfied: click in /home/trusted-service-user/cluster-env/env/lib/python3.10/site-packages (from nltk) (8.1.7)\r\nRequirement already satisfied: joblib in /home/trusted-service-user/cluster-env/env/lib/python3.10/site-packages (from nltk) (1.3.2)\r\nRequirement already satisfied: regex>=2021.8.3 in /home/trusted-service-user/cluster-env/env/lib/python3.10/site-packages (from nltk) (2023.12.25)\r\nRequirement already satisfied: tqdm in /home/trusted-service-user/cluster-env/env/lib/python3.10/site-packages (from nltk) (4.66.2)\r\nRequirement already satisfied: charset-normalizer<4,>=2 in /home/trusted-service-user/cluster-env/env/lib/python3.10/site-packages (from requests->vaderSentiment) (3.3.2)\r\nRequirement already satisfied: idna<4,>=2.5 in /home/trusted-service-user/cluster-env/env/lib/python3.10/site-packages (from requests->vaderSentiment) (3.6)\r\nRequirement already satisfied: urllib3<3,>=1.21.1 in /home/trusted-service-user/cluster-env/env/lib/python3.10/site-packages (from requests->vaderSentiment) (2.1.0)\r\nRequirement already satisfied: certifi>=2017.4.17 in /home/trusted-service-user/cluster-env/env/lib/python3.10/site-packages (from requests->vaderSentiment) (2024.2.2)\r\n"
        }
      ],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "!pip install vaderSentiment langdetect emoji nltk vaderSentiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "spark0624",
              "session_id": "9",
              "statement_id": 9,
              "statement_ids": [
                9
              ],
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2024-06-24T12:28:43.9384869Z",
              "session_start_time": null,
              "execution_start_time": "2024-06-24T12:28:47.0427242Z",
              "execution_finish_time": "2024-06-24T12:28:47.2032959Z",
              "spark_jobs": null,
              "parent_msg_id": "27b72905-6d11-4be4-b7d5-601fb383efc0"
            },
            "text/plain": "StatementMeta(spark0624, 9, 9, Finished, Available)"
          },
          "metadata": {}
        }
      ],
      "metadata": {},
      "source": [
        "from pyspark.sql.functions import udf,monotonically_increasing_id\r\n",
        "from pyspark.sql.types import StringType, FloatType\r\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\r\n",
        "from pyspark.sql import functions as f  \r\n",
        "import requests\r\n",
        "import pandas as pd \r\n",
        "import datetime\r\n",
        "import emoji\r\n",
        "import nltk\r\n",
        "from langdetect import detect\r\n",
        "from langdetect.lang_detect_exception import LangDetectException\r\n",
        "from nltk.corpus import stopwords\r\n",
        "from nltk.tokenize import word_tokenize\r\n",
        "import string\r\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\r\n",
        "from notebookutils import mssparkutils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "spark0624",
              "session_id": "9",
              "statement_id": 10,
              "statement_ids": [
                10
              ],
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2024-06-24T12:28:43.9996132Z",
              "session_start_time": null,
              "execution_start_time": "2024-06-24T12:28:47.3416862Z",
              "execution_finish_time": "2024-06-24T12:28:47.5020672Z",
              "spark_jobs": null,
              "parent_msg_id": "5e2bf951-8b7e-404b-981c-5879580c4ca6"
            },
            "text/plain": "StatementMeta(spark0624, 9, 10, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "[nltk_data] Downloading package punkt to /home/trusted-service-\n[nltk_data]     user/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package stopwords to /home/trusted-service-\n[nltk_data]     user/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "True"
          },
          "execution_count": 21,
          "metadata": {}
        }
      ],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "nltk.download('punkt')\r\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "spark0624",
              "session_id": "9",
              "statement_id": 11,
              "statement_ids": [
                11
              ],
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2024-06-24T12:28:44.0845551Z",
              "session_start_time": null,
              "execution_start_time": "2024-06-24T12:28:47.6748341Z",
              "execution_finish_time": "2024-06-24T12:28:48.2219774Z",
              "spark_jobs": null,
              "parent_msg_id": "953aa618-e94f-4648-9b34-ec2d28c60e92"
            },
            "text/plain": "StatementMeta(spark0624, 9, 11, Finished, Available)"
          },
          "metadata": {}
        }
      ],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# read file \r\n",
        "datalake_nm = 'datalake'+mssparkutils.env.getWorkspaceName()[7:] # get datalake name \r\n",
        "file_path ='abfss://files@{0}.dfs.core.windows.net/synapse/workspaces/data/youtube/youtube_cms'.format(datalake_nm)\r\n",
        "Youtube_df = spark.read.parquet(file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "spark0624",
              "session_id": "9",
              "statement_id": 12,
              "statement_ids": [
                12
              ],
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2024-06-24T12:28:44.2274357Z",
              "session_start_time": null,
              "execution_start_time": "2024-06-24T12:28:48.3692519Z",
              "execution_finish_time": "2024-06-24T12:28:55.2998655Z",
              "spark_jobs": null,
              "parent_msg_id": "3969869c-a042-41a6-a5f6-4e4fead1b6d9"
            },
            "text/plain": "StatementMeta(spark0624, 9, 12, Finished, Available)"
          },
          "metadata": {}
        }
      ],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Filter on words Count\r\n",
        "Youtube_df_v1 = (\r\n",
        "    Youtube_df.withColumn('wordCount', f.size(f.split(f.col('comment'), ' ')))\r\n",
        "    .filter(f.col('wordCount')>5)\r\n",
        "    .withColumn(\"id\", monotonically_increasing_id())\r\n",
        "    .select('Date','id','Comment','symbol','VideoID')\r\n",
        "    ).toPandas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "spark0624",
              "session_id": "9",
              "statement_id": 13,
              "statement_ids": [
                13
              ],
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2024-06-24T12:28:44.3499213Z",
              "session_start_time": null,
              "execution_start_time": "2024-06-24T12:28:55.4425763Z",
              "execution_finish_time": "2024-06-24T12:28:55.5959342Z",
              "spark_jobs": null,
              "parent_msg_id": "d9474f05-706b-44be-9f57-6d16c0800add"
            },
            "text/plain": "StatementMeta(spark0624, 9, 13, Finished, Available)"
          },
          "metadata": {}
        }
      ],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# remove non english word\r\n",
        "def is_english(text):\r\n",
        "    try:\r\n",
        "        return detect(text) == 'en'\r\n",
        "    except LangDetectException:\r\n",
        "        return False\r\n",
        "    \r\n",
        "# change text into lowercase\r\n",
        "def to_lowercase(text):\r\n",
        "    return text.lower()\r\n",
        "\r\n",
        "# remove punctuation\r\n",
        "def rm_punctuation(text):\r\n",
        "    return text.translate(str.maketrans('', '', string.punctuation))\r\n",
        "\r\n",
        "def tokenise(text):\r\n",
        "    return word_tokenize(text)\r\n",
        "\r\n",
        "# remove stop words \r\n",
        "def remove_stopwords(tokens):\r\n",
        "    stop_words = set(stopwords.words('english'))\r\n",
        "    return [word for word in tokens if word not in stop_words]\r\n",
        "\r\n",
        "# rejoin tokens\r\n",
        "def rejoin_tokens(tokens):\r\n",
        "    return ' '.join(tokens)\r\n",
        "\r\n",
        "# main function for preprocess_text \r\n",
        "def preprocess_text(text):\r\n",
        "    text = to_lowercase(text)\r\n",
        "    text = rm_punctuation(text)\r\n",
        "    tokens = tokenise(text)\r\n",
        "    tokens = remove_stopwords(tokens)\r\n",
        "    return rejoin_tokens(tokens)\r\n",
        "\r\n",
        "def is_string(text):\r\n",
        "    return isinstance(text, str)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## 1. Data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "spark0624",
              "session_id": "9",
              "statement_id": 14,
              "statement_ids": [
                14
              ],
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2024-06-24T12:28:44.4314595Z",
              "session_start_time": null,
              "execution_start_time": "2024-06-24T12:28:55.7424714Z",
              "execution_finish_time": "2024-06-24T12:30:00.0719456Z",
              "spark_jobs": null,
              "parent_msg_id": "7cc040c1-2e8c-451c-a1b7-943b30f7d6be"
            },
            "text/plain": "StatementMeta(spark0624, 9, 14, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "/tmp/ipykernel_55203/3932524745.py:6: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  Youtube_df_v2['preprocessed_text'] = Youtube_df_v2['Comment'].apply(preprocess_text)\n/tmp/ipykernel_55203/3932524745.py:9: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  Youtube_df_v2['is_string']=Youtube_df_v2['preprocessed_text'].apply(is_string)\n"
        }
      ],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Remove content is not english\r\n",
        "Youtube_df_v1['is_english'] = Youtube_df_v1['Comment'].apply(is_english)\r\n",
        "Youtube_df_v2 = Youtube_df_v1[Youtube_df_v1['is_english']]\r\n",
        "\r\n",
        "# data preapration\r\n",
        "Youtube_df_v2['preprocessed_text'] = Youtube_df_v2['Comment'].apply(preprocess_text)\r\n",
        "\r\n",
        "# remove content is not string\r\n",
        "Youtube_df_v2['is_string']=Youtube_df_v2['preprocessed_text'].apply(is_string)\r\n",
        "Youtube_df_v3 = Youtube_df_v2[Youtube_df_v2['is_string']]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# 2. Sentiment analysis with vader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "spark0624",
              "session_id": "9",
              "statement_id": 15,
              "statement_ids": [
                15
              ],
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2024-06-24T12:28:44.5352686Z",
              "session_start_time": null,
              "execution_start_time": "2024-06-24T12:30:00.242582Z",
              "execution_finish_time": "2024-06-24T12:30:00.400036Z",
              "spark_jobs": null,
              "parent_msg_id": "83eededf-0c70-412d-bfc7-a84175f086c7"
            },
            "text/plain": "StatementMeta(spark0624, 9, 15, Finished, Available)"
          },
          "metadata": {}
        }
      ],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "def analyze_sentiment(text):\r\n",
        "    analyzer = SentimentIntensityAnalyzer()\r\n",
        "    scores = analyzer.polarity_scores(text)\r\n",
        "    return scores['compound']\r\n",
        "\r\n",
        "def categorize_sentiment(compound_score):\r\n",
        "    if compound_score >= 0.05:\r\n",
        "        return 'positive'\r\n",
        "    elif compound_score <= -0.05:\r\n",
        "        return 'negative'\r\n",
        "    else:\r\n",
        "        return 'neutral'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "spark0624",
              "session_id": "9",
              "statement_id": 16,
              "statement_ids": [
                16
              ],
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2024-06-24T12:28:44.7387112Z",
              "session_start_time": null,
              "execution_start_time": "2024-06-24T12:30:00.5435701Z",
              "execution_finish_time": "2024-06-24T12:32:04.7975697Z",
              "spark_jobs": null,
              "parent_msg_id": "afc65626-2e11-4c35-8ef9-02c090f0a0ca"
            },
            "text/plain": "StatementMeta(spark0624, 9, 16, Finished, Available)"
          },
          "metadata": {}
        }
      ],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "Youtube_df_v3['sentiment'] = Youtube_df_v3['preprocessed_text'].apply(analyze_sentiment)\r\n",
        "Youtube_df_v3['sentiment_category'] = Youtube_df_v3['sentiment'].apply(categorize_sentiment)\r\n",
        "Youtube_df_v4 = Youtube_df_v3[['id','sentiment','sentiment_category']]\r\n",
        "final_df = pd.merge(Youtube_df_v1,Youtube_df_v4, left_on='id', right_on='id', how='left')\r\n",
        "result = final_df[['Date','symbol','Comment','sentiment','sentiment_category']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "spark0624",
              "session_id": "9",
              "statement_id": 17,
              "statement_ids": [
                17
              ],
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2024-06-24T12:28:44.8483085Z",
              "session_start_time": null,
              "execution_start_time": "2024-06-24T12:32:04.9436205Z",
              "execution_finish_time": "2024-06-24T12:32:09.0687553Z",
              "spark_jobs": null,
              "parent_msg_id": "36c99fb9-9e91-4536-bd64-cc83a4c53311"
            },
            "text/plain": "StatementMeta(spark0624, 9, 17, Finished, Available)"
          },
          "metadata": {}
        }
      ],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "spdf = spark.createDataFrame(result)\r\n",
        "datalake_nm = 'datalake'+mssparkutils.env.getWorkspaceName()[7:] # get datalake name \r\n",
        "file_path ='abfss://files@{0}.dfs.core.windows.net/synapse/workspaces/data/youtube/youtube_sentiments'.format(datalake_nm)\r\n",
        "spdf.write.parquet(file_path,mode='overwrite')"
      ]
    }
  ],
  "metadata": {
    "description": null,
    "save_output": true,
    "language_info": {
      "name": "python"
    },
    "synapse_widget": {
      "version": "0.1",
      "state": {}
    }
  }
}