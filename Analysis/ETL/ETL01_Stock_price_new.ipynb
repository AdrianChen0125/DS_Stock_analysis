{
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "!pip install yfinance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "import yfinance as yf\r\n",
        "from pyspark.sql.types import *\r\n",
        "from pyspark.sql import functions as f\r\n",
        "import requests\r\n",
        "import pandas as pd \r\n",
        "import datetime\r\n",
        "from notebookutils import mssparkutils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "outputs": [],
      "metadata": {},
      "source": [
        "def get_stock_price(symbol_list,start_date,end_date):\r\n",
        "    historical_data = {}\r\n",
        "    for symbol in symbol_list:\r\n",
        "        ticker = yf.Ticker(symbol)\r\n",
        "        data = ticker.history(start=start_date, end=end_date)\r\n",
        "        historical_data[symbol] = data\r\n",
        "\r\n",
        "    return historical_data\r\n",
        "\r\n",
        "def transform_df(historical_data,symbol_list):\r\n",
        "    dfs=[]\r\n",
        "    for symbol in symbol_list:\r\n",
        "        df = pd.DataFrame(historical_data[symbol])\r\n",
        "        df['symbol']= symbol\r\n",
        "        dfs.append(df)\r\n",
        "    df = pd.concat(dfs).reset_index()\r\n",
        "    df['Date'] = df['Date'].dt.date\r\n",
        "    return df "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "if __name__ == \"__main__\":\r\n",
        "    \r\n",
        "    symbol_list=['NVDA','AMD','INTC','QCOM','GOOG','MSFT','AMZN','AAPL'] # ticker list\r\n",
        "\r\n",
        "    # set up date range\r\n",
        "    end_date = datetime.datetime.now()\r\n",
        "    start_date = end_date-datetime.timedelta(days=5*365)\r\n",
        "\r\n",
        "    # Query data \r\n",
        "    historical_data = get_stock_price(symbol_list,start_date,end_date)\r\n",
        "    pdf = transform_df(historical_data,symbol_list)\r\n",
        "    sp_df = spark.createDataFrame(pdf)\r\n",
        "    \r\n",
        "    # Write dataframe into csv in data lake \r\n",
        "    datalake_nm = 'datalake'+mssparkutils.env.getWorkspaceName()[7:] # get datalake name \r\n",
        "    file_path ='abfss://files@{0}.dfs.core.windows.net/synapse/workspaces/data/stock_price'.format(datalake_nm)\r\n",
        "    sp_df.write.option(\"header\", True).csv(file_path,mode='overwrite')"
      ]
    }
  ],
  "metadata": {
    "description": null,
    "save_output": true,
    "language_info": {
      "name": "python"
    }
  }
}